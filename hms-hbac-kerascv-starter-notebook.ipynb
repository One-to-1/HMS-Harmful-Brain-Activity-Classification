{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-01-10T05:24:31.308329Z","iopub.status.busy":"2024-01-10T05:24:31.307595Z","iopub.status.idle":"2024-01-10T05:24:31.313088Z","shell.execute_reply":"2024-01-10T05:24:31.312113Z","shell.execute_reply.started":"2024-01-10T05:24:31.308287Z"},"papermill":{"duration":0.011755,"end_time":"2024-01-14T03:16:16.447481","exception":false,"start_time":"2024-01-14T03:16:16.435726","status":"completed"},"tags":[]},"source":["<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n","This starter notebook is provided by the Keras team.</center>"]},{"cell_type":"markdown","metadata":{},"source":["# HMS - Harmful Brain Activity Classification with [KerasCV](https://github.com/keras-team/keras-cv) and [Keras](https://github.com/keras-team/keras)\n","\n","> The objective of this competition is to classify seizures and other patterns of harmful brain activity in critically ill patients\n","\n","This notebook guides you through the process of training and inferring a Deep Learning model, specifically EfficientNetV2, using KerasCV on the competition dataset. Specificaclly, this notebook uses spectrogram of the eeg data to classify the patterns.\n","\n","Fun fact: This notebook is backend-agnostic, supporting TensorFlow, PyTorch, and JAX. Utilizing KerasCV and Keras allows us to choose our preferred backend. Explore more details on [Keras](https://keras.io/keras_core/announcement/).\n","\n","In this notebook, you will learn:\n","\n","* Loading the data efficiently using [`tf.data`](https://www.tensorflow.org/guide/data).\n","* Creating the model using KerasCV presets.\n","* Training the model.\n","* Inference and Submission on test data.\n","\n","**Note**: For a more in-depth understanding of KerasCV, refer to the [KerasCV guides](https://keras.io/guides/keras_cv/)."]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011416,"end_time":"2024-01-14T03:16:16.470167","exception":false,"start_time":"2024-01-14T03:16:16.458751","status":"completed"},"tags":[]},"source":["# ðŸ›  | Install Libraries  \n","\n","Since internet access is **disabled** during inference, we cannot install libraries in the usual `!pip install <lib_name>` manner. Instead, we need to install libraries from local files. In the following cell, we will install libraries from our local files. The installation code stays very similar - we just use the `filepath` instead of the `filename` of the library. So now the code is `!pip install <local_filepath>`. \n","\n","> The `filepath` of these local libraries look quite complicated, but don't be intimidated! Also `--no-deps` argument ensures that we are not installing any additional libraries."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:09:58.472046Z","iopub.status.busy":"2024-02-01T08:09:58.471669Z","iopub.status.idle":"2024-02-01T08:11:45.612735Z","shell.execute_reply":"2024-02-01T08:11:45.611628Z","shell.execute_reply.started":"2024-02-01T08:09:58.472001Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.10.0)\n","Collecting tensorflow\n","  Using cached tensorflow-2.16.1-cp310-cp310-win_amd64.whl (2.1 kB)\n","Collecting tensorflow-intel==2.16.1\n","  Downloading tensorflow_intel-2.16.1-cp310-cp310-win_amd64.whl (376.9 MB)\n","     -------------------------------------- 376.9/376.9 MB 3.3 MB/s eta 0:00:00\n","Collecting tensorboard<2.17,>=2.16\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","     ---------------------------------------- 5.5/5.5 MB 5.6 MB/s eta 0:00:00\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n","Collecting keras>=3.0.0\n","  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n","     ---------------------------------------- 1.0/1.0 MB 4.7 MB/s eta 0:00:00\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.42.0)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n","Collecting h5py>=3.10.0\n","  Downloading h5py-3.10.0-cp310-cp310-win_amd64.whl (2.7 MB)\n","     ---------------------------------------- 2.7/2.7 MB 6.1 MB/s eta 0:00:00\n","Collecting ml-dtypes~=0.3.1\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-win_amd64.whl (127 kB)\n","     -------------------------------------- 127.8/127.8 kB 2.5 MB/s eta 0:00:00\n","Collecting flatbuffers>=23.5.26\n","  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n","Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.4.0)\n","Collecting libclang>=13.0.0\n","  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n","     ---------------------------------------- 24.4/24.4 MB 6.3 MB/s eta 0:00:00\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.23.5)\n","Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.6.3)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n","     ---------------------------------------- 1.5/1.5 MB 11.8 MB/s eta 0:00:00\n","Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (22.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n","Requirement already satisfied: dm-tree in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.8)\n","Requirement already satisfied: rich in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.14)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n","Collecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.62.1-cp310-cp310-win_amd64.whl (3.8 MB)\n","     ---------------------------------------- 3.8/3.8 MB 7.6 MB/s eta 0:00:00\n","Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\yatharth jain\\appdata\\roaming\\python\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n","Installing collected packages: libclang, flatbuffers, tensorflow-io-gcs-filesystem, tensorboard-data-server, ml-dtypes, h5py, grpcio, tensorboard, keras, tensorflow-intel, tensorflow\n","Successfully installed flatbuffers-24.3.7 grpcio-1.62.1 h5py-3.10.0 keras-3.0.5 libclang-16.0.6 ml-dtypes-0.3.2 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\Yatharth Jain\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n","  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\Yatharth Jain\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n","  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"]}],"source":["!pip install --upgrade tensorflow"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010878,"end_time":"2024-01-14T03:17:49.510159","exception":false,"start_time":"2024-01-14T03:17:49.499281","status":"completed"},"tags":[]},"source":["# ðŸ“š | Import Libraries "]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-02-01T08:11:45.615026Z","iopub.status.busy":"2024-02-01T08:11:45.614724Z","iopub.status.idle":"2024-02-01T08:11:56.499875Z","shell.execute_reply":"2024-02-01T08:11:56.499055Z","shell.execute_reply.started":"2024-02-01T08:11:45.615Z"},"papermill":{"duration":10.671979,"end_time":"2024-01-14T03:18:00.193134","exception":false,"start_time":"2024-01-14T03:17:49.521155","status":"completed"},"tags":[],"trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"The Tensorflow package version needs to be at least 2.11.0 for KerasCV to run. Currently, your TensorFlow version is 2.10.0. Please upgrade with `$ pip install --upgrade tensorflow`. You can use `pip freeze` to check afterwards that everything is ok.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERAS_BACKEND\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# you can also use tensorflow or torch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_cv\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bounding_box\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_cv\\bounding_box\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_format\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensure_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_tensor\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbounding_box\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CENTER_XYWH\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_cv\\src\\__init__.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# isort:off\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_check\n\u001b[1;32m---> 27\u001b[0m \u001b[43mversion_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_tf_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# isort:on\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_cv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bounding_box\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_cv\\src\\version_check.py:34\u001b[0m, in \u001b[0;36mcheck_tf_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_tf_version\u001b[39m():\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(tf\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse(MIN_VERSION):\n\u001b[1;32m---> 34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     35\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Tensorflow package version needs to be at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for KerasCV to run. Currently, your TensorFlow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please upgrade with `$ pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--upgrade tensorflow`. You can use `pip freeze` to check \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafterwards that everything is ok.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     40\u001b[0m         )\n","\u001b[1;31mRuntimeError\u001b[0m: The Tensorflow package version needs to be at least 2.11.0 for KerasCV to run. Currently, your TensorFlow version is 2.10.0. Please upgrade with `$ pip install --upgrade tensorflow`. You can use `pip freeze` to check afterwards that everything is ok."]}],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n","\n","import keras_cv\n","import keras\n","from keras import ops\n","import tensorflow as tf\n","\n","import cv2\n","import pandas as pd\n","import numpy as np\n","from glob import glob\n","from tqdm.notebook import tqdm\n","import joblib\n","\n","import matplotlib.pyplot as plt "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010958,"end_time":"2024-01-14T03:18:00.215704","exception":false,"start_time":"2024-01-14T03:18:00.204746","status":"completed"},"tags":[]},"source":["## Library Versions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:56.501441Z","iopub.status.busy":"2024-02-01T08:11:56.500924Z","iopub.status.idle":"2024-02-01T08:11:56.506615Z","shell.execute_reply":"2024-02-01T08:11:56.505678Z","shell.execute_reply.started":"2024-02-01T08:11:56.501416Z"},"papermill":{"duration":0.019435,"end_time":"2024-01-14T03:18:00.246368","exception":false,"start_time":"2024-01-14T03:18:00.226933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["print(\"TensorFlow:\", tf.__version__)\n","print(\"Keras:\", keras.__version__)\n","print(\"KerasCV:\", keras_cv.__version__)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010922,"end_time":"2024-01-14T03:18:00.26855","exception":false,"start_time":"2024-01-14T03:18:00.257628","status":"completed"},"tags":[]},"source":["# âš™ï¸ | Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:56.510141Z","iopub.status.busy":"2024-02-01T08:11:56.509498Z","iopub.status.idle":"2024-02-01T08:11:56.526461Z","shell.execute_reply":"2024-02-01T08:11:56.525619Z","shell.execute_reply.started":"2024-02-01T08:11:56.51011Z"},"papermill":{"duration":0.018795,"end_time":"2024-01-14T03:18:00.298534","exception":false,"start_time":"2024-01-14T03:18:00.279739","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class CFG:\n","    verbose = 1  # Verbosity\n","    seed = 42  # Random seed\n","    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n","    image_size = [400, 300]  # Input image size\n","    epochs = 13 # Training epochs\n","    batch_size = 64  # Batch size\n","    lr_mode = \"cos\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n","    drop_remainder = True  # Drop incomplete batches\n","    num_classes = 6 # Number of classes in the dataset\n","    fold = 0 # Which fold to set as validation data\n","    class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\n","    label2name = dict(enumerate(class_names))\n","    name2label = {v:k for k, v in label2name.items()}"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010907,"end_time":"2024-01-14T03:18:00.32063","exception":false,"start_time":"2024-01-14T03:18:00.309723","status":"completed"},"tags":[]},"source":["# â™»ï¸ | Reproducibility \n","Sets value for random seed to produce similar result in each run."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:56.527893Z","iopub.status.busy":"2024-02-01T08:11:56.527613Z","iopub.status.idle":"2024-02-01T08:11:56.536142Z","shell.execute_reply":"2024-02-01T08:11:56.535296Z","shell.execute_reply.started":"2024-02-01T08:11:56.527869Z"},"papermill":{"duration":0.018371,"end_time":"2024-01-14T03:18:00.350074","exception":false,"start_time":"2024-01-14T03:18:00.331703","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["keras.utils.set_random_seed(CFG.seed)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.010888,"end_time":"2024-01-14T03:18:00.372053","exception":false,"start_time":"2024-01-14T03:18:00.361165","status":"completed"},"tags":[]},"source":["# ðŸ“ | Dataset Path "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:56.5375Z","iopub.status.busy":"2024-02-01T08:11:56.537196Z","iopub.status.idle":"2024-02-01T08:11:56.548849Z","shell.execute_reply":"2024-02-01T08:11:56.548017Z","shell.execute_reply.started":"2024-02-01T08:11:56.537478Z"},"papermill":{"duration":0.017704,"end_time":"2024-01-14T03:18:00.400852","exception":false,"start_time":"2024-01-14T03:18:00.383148","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["BASE_PATH = \"/kaggle/input/hms-harmful-brain-activity-classification\"\n","\n","SPEC_DIR = \"/tmp/dataset/hms-hbac\"\n","os.makedirs(SPEC_DIR+'/train_spectrograms', exist_ok=True)\n","os.makedirs(SPEC_DIR+'/test_spectrograms', exist_ok=True)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011434,"end_time":"2024-01-14T03:18:00.472401","exception":false,"start_time":"2024-01-14T03:18:00.460967","status":"completed"},"tags":[]},"source":["# ðŸ“– | Meta Data "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:56.550129Z","iopub.status.busy":"2024-02-01T08:11:56.549878Z","iopub.status.idle":"2024-02-01T08:11:57.142269Z","shell.execute_reply":"2024-02-01T08:11:57.141377Z","shell.execute_reply.started":"2024-02-01T08:11:56.550108Z"},"trusted":true},"outputs":[],"source":["# Train + Valid\n","df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","df['eeg_path'] = f'{BASE_PATH}/train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\n","df['spec_path'] = f'{BASE_PATH}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\n","df['spec2_path'] = f'{SPEC_DIR}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.npy'\n","df['class_name'] = df.expert_consensus.copy()\n","df['class_label'] = df.expert_consensus.map(CFG.name2label)\n","display(df.head(2))\n","\n","# Test\n","test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n","test_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\n","test_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'\n","test_df['spec2_path'] = f'{SPEC_DIR}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.npy'\n","display(test_df.head(2))"]},{"cell_type":"markdown","metadata":{},"source":["## Convert `.parquet` to `.npy`\n","\n","To facilitate easier data loading, we will convert the EEG spectrograms from `parquet` to `npy` format. This process involves saving the spectrogram data, and since the content of the files remains the same, no significant changes are made. \n","\n","> It's worth noting that the `time` column is excluded, as it is not part of the spectrogram."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:11:57.143667Z","iopub.status.busy":"2024-02-01T08:11:57.143405Z","iopub.status.idle":"2024-02-01T08:14:58.676582Z","shell.execute_reply":"2024-02-01T08:14:58.675463Z","shell.execute_reply.started":"2024-02-01T08:11:57.143644Z"},"papermill":{"duration":0.86264,"end_time":"2024-01-14T03:18:01.346487","exception":false,"start_time":"2024-01-14T03:18:00.483847","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Define a function to process a single eeg_id\n","def process_spec(spec_id, split=\"train\"):\n","    spec_path = f\"{BASE_PATH}/{split}_spectrograms/{spec_id}.parquet\"\n","    spec = pd.read_parquet(spec_path)\n","    spec = spec.fillna(0).values[:, 1:].T # fill NaN values with 0, transpose for (Time, Freq) -> (Freq, Time)\n","    spec = spec.astype(\"float32\")\n","    np.save(f\"{SPEC_DIR}/{split}_spectrograms/{spec_id}.npy\", spec)\n","\n","# Get unique spec_ids of train and valid data\n","spec_ids = df[\"spectrogram_id\"].unique()\n","\n","# Parallelize the processing using joblib for training data\n","_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n","    joblib.delayed(process_spec)(spec_id, \"train\")\n","    for spec_id in tqdm(spec_ids, total=len(spec_ids))\n",")\n","\n","# Get unique spec_ids of test data\n","test_spec_ids = test_df[\"spectrogram_id\"].unique()\n","\n","# Parallelize the processing using joblib for test data\n","_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n","    joblib.delayed(process_spec)(spec_id, \"test\")\n","    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))\n",")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011843,"end_time":"2024-01-14T03:18:01.457956","exception":false,"start_time":"2024-01-14T03:18:01.446113","status":"completed"},"tags":[]},"source":["# ðŸš | DataLoader\n","\n","This DataLoader first reads `npy` spectrogram files and extracts labeled subsamples using specified `offset` values. Then, it converts the spectrogram data into `log spectrogram` and applies the popular signal augmentation `MixUp`.\n","\n","> Note that, we are converting the mono channel signal to a 3-channel signal for using \"ImageNet\" weights of pretrained model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:17:27.279117Z","iopub.status.busy":"2024-02-01T08:17:27.278733Z","iopub.status.idle":"2024-02-01T08:17:27.300354Z","shell.execute_reply":"2024-02-01T08:17:27.299141Z","shell.execute_reply.started":"2024-02-01T08:17:27.279091Z"},"papermill":{"duration":0.039133,"end_time":"2024-01-14T03:18:01.509017","exception":false,"start_time":"2024-01-14T03:18:01.469884","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def build_augmenter(dim=CFG.image_size):\n","    augmenters = [\n","        keras_cv.layers.MixUp(alpha=2.0),\n","        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n","                                     width_factor=(0.06, 0.1)), # freq-masking\n","        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n","                                     width_factor=(1.0, 1.0)), # time-masking\n","    ]\n","    \n","    def augment(img, label):\n","        data = {\"images\":img, \"labels\":label}\n","        for augmenter in augmenters:\n","            if tf.random.uniform([]) < 0.5:\n","                data = augmenter(data, training=True)\n","        return data[\"images\"], data[\"labels\"]\n","    \n","    return augment\n","\n","\n","def build_decoder(with_labels=True, target_size=CFG.image_size, dtype=32):\n","    def decode_signal(path, offset=None):\n","        # Read .npy files and process the signal\n","        file_bytes = tf.io.read_file(path)\n","        sig = tf.io.decode_raw(file_bytes, tf.float32)\n","        sig = sig[1024//dtype:]  # Remove header tag\n","        sig = tf.reshape(sig, [400, -1])\n","        \n","        # Extract labeled subsample from full spectrogram using \"offset\"\n","        if offset is not None: \n","            offset = offset // 2  # Only odd values are given\n","            sig = sig[:, offset:offset+300]\n","            \n","            # Pad spectrogram to ensure the same input shape of [400, 300]\n","            pad_size = tf.math.maximum(0, 300 - tf.shape(sig)[1])\n","            sig = tf.pad(sig, [[0, 0], [0, pad_size]])\n","            sig = tf.reshape(sig, [400, 300])\n","        \n","        # Log spectrogram \n","        sig = tf.clip_by_value(sig, tf.math.exp(-4.0), tf.math.exp(8.0)) # avoid 0 in log\n","        sig = tf.math.log(sig)\n","        \n","        # Normalize spectrogram\n","        sig -= tf.math.reduce_mean(sig)\n","        sig /= tf.math.reduce_std(sig) + 1e-6\n","        \n","        # Mono channel to 3 channels to use \"ImageNet\" weights\n","        sig = tf.tile(sig[..., None], [1, 1, 3])\n","        return sig\n","    \n","    def decode_label(label):\n","        label = tf.one_hot(label, CFG.num_classes)\n","        label = tf.cast(label, tf.float32)\n","        label = tf.reshape(label, [CFG.num_classes])\n","        return label\n","    \n","    def decode_with_labels(path, offset=None, label=None):\n","        sig = decode_signal(path, offset)\n","        label = decode_label(label)\n","        return (sig, label)\n","    \n","    return decode_with_labels if with_labels else decode_signal\n","\n","\n","def build_dataset(paths, offsets=None, labels=None, batch_size=32, cache=True,\n","                  decode_fn=None, augment_fn=None,\n","                  augment=False, repeat=True, shuffle=1024, \n","                  cache_dir=\"\", drop_remainder=False):\n","    if cache_dir != \"\" and cache is True:\n","        os.makedirs(cache_dir, exist_ok=True)\n","    \n","    if decode_fn is None:\n","        decode_fn = build_decoder(labels is not None)\n","    \n","    if augment_fn is None:\n","        augment_fn = build_augmenter()\n","    \n","    AUTO = tf.data.experimental.AUTOTUNE\n","    slices = (paths, offsets) if labels is None else (paths, offsets, labels)\n","    \n","    ds = tf.data.Dataset.from_tensor_slices(slices)\n","    ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n","    ds = ds.cache(cache_dir) if cache else ds\n","    ds = ds.repeat() if repeat else ds\n","    if shuffle: \n","        ds = ds.shuffle(shuffle, seed=CFG.seed)\n","        opt = tf.data.Options()\n","        opt.experimental_deterministic = False\n","        ds = ds.with_options(opt)\n","    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n","    ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n","    ds = ds.prefetch(AUTO)\n","    return ds"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.012174,"end_time":"2024-01-14T03:18:01.538524","exception":false,"start_time":"2024-01-14T03:18:01.52635","status":"completed"},"tags":[]},"source":["# ðŸ”ª | Data Split\n","\n","In the following code snippet, the data is divided into `5` folds. Note that, the `groups` argument is used to prevent any overlap of patients between the training and validation sets, thus avoiding potential **data leakage** issues. Additionally, each split is stratified based on the `class_label`, ensuring a uniform distribution of class labels in each fold."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:14:58.702904Z","iopub.status.busy":"2024-02-01T08:14:58.702622Z","iopub.status.idle":"2024-02-01T08:15:01.163856Z","shell.execute_reply":"2024-02-01T08:15:01.162898Z","shell.execute_reply.started":"2024-02-01T08:14:58.702882Z"},"papermill":{"duration":0.037496,"end_time":"2024-01-14T03:18:01.587924","exception":false,"start_time":"2024-01-14T03:18:01.550428","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedGroupKFold\n","\n","sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n","\n","df[\"fold\"] = -1\n","df.reset_index(drop=True, inplace=True)\n","for fold, (train_idx, valid_idx) in enumerate(\n","    sgkf.split(df, y=df[\"class_label\"], groups=df[\"patient_id\"])\n","):\n","    df.loc[valid_idx, \"fold\"] = fold\n","df.groupby([\"fold\", \"class_name\"])[[\"eeg_id\"]].count().T"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.011875,"end_time":"2024-01-14T03:18:01.611955","exception":false,"start_time":"2024-01-14T03:18:01.60008","status":"completed"},"tags":[]},"source":["## Build Train & Valid Dataset\n","\n","Only first sample for each `spectrogram_id` is used in order to keep the dataset size managable. Feel free to train on full data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-01T08:17:29.652748Z","iopub.status.busy":"2024-02-01T08:17:29.652278Z","iopub.status.idle":"2024-02-01T08:17:30.626157Z","shell.execute_reply":"2024-02-01T08:17:30.625103Z","shell.execute_reply.started":"2024-02-01T08:17:29.652709Z"},"trusted":true},"outputs":[],"source":["# Sample from full data\n","sample_df = df.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\n","train_df = sample_df[sample_df.fold != CFG.fold]\n","valid_df = sample_df[sample_df.fold == CFG.fold]\n","print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")\n","\n","# Train\n","train_paths = train_df.spec2_path.values\n","train_offsets = train_df.spectrogram_label_offset_seconds.values.astype(int)\n","train_labels = train_df.class_label.values\n","train_ds = build_dataset(train_paths, train_offsets, train_labels, batch_size=CFG.batch_size,\n","                         repeat=True, shuffle=True, augment=True, cache=True)\n","\n","# Valid\n","valid_paths = valid_df.spec2_path.values\n","valid_offsets = valid_df.spectrogram_label_offset_seconds.values.astype(int)\n","valid_labels = valid_df.class_label.values\n","valid_ds = build_dataset(valid_paths, valid_offsets, valid_labels, batch_size=CFG.batch_size,\n","                         repeat=False, shuffle=False, augment=False, cache=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Check\n","\n","Let's visualize some samples from the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-02-01T08:17:33.806415Z","iopub.status.busy":"2024-02-01T08:17:33.806036Z","iopub.status.idle":"2024-02-01T08:17:37.720083Z","shell.execute_reply":"2024-02-01T08:17:37.718626Z","shell.execute_reply.started":"2024-02-01T08:17:33.806385Z"},"trusted":true},"outputs":[],"source":["imgs, tars = next(iter(train_ds))\n","\n","num_imgs = 8\n","plt.figure(figsize=(4*4, num_imgs//4*5))\n","for i in range(num_imgs):\n","    plt.subplot(num_imgs//4, 4, i + 1)\n","    img = imgs[i].numpy()[...,0]  # Adjust as per your image data format\n","    img -= img.min()\n","    img /= img.max() + 1e-4\n","    tar = CFG.label2name[np.argmax(tars[i].numpy())]\n","    plt.imshow(img)\n","    plt.title(f\"Target: {tar}\")\n","    plt.axis('off')\n","    \n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ” | Loss & Metric\n","\n","The evaluation metric in this competition is **KL Divergence**, defined as,\n","\n","$$\n","D_{\\text{KL}}(P \\parallel Q) = \\sum_{i} P(i) \\log\\left(\\frac{P(i)}{Q(i)}\\right)\n","$$\n","\n","Where:\n","- $P$ is the true distribution.\n","- $Q$ is the predicted distribution.\n","\n","Interestingly, as KL Divergence is differentiable, we can directly use it as our loss function. Thus, we don't need to use a third-party metric like **Accuracy** to evaluate our model. Therefore, `valid_loss` can stand alone as an indicator for our evaluation. In keras, we already have impelementation for KL Divergence loss so we only need to import it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:23.764307Z","iopub.status.busy":"2024-01-21T08:11:23.763944Z","iopub.status.idle":"2024-01-21T08:11:23.770792Z","shell.execute_reply":"2024-01-21T08:11:23.768924Z","shell.execute_reply.started":"2024-01-21T08:11:23.764273Z"},"trusted":true},"outputs":[],"source":["LOSS = keras.losses.KLDivergence()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016849,"end_time":"2024-01-14T03:18:38.613991","exception":false,"start_time":"2024-01-14T03:18:38.597142","status":"completed"},"tags":[]},"source":["# ðŸ¤– | Modeling\n","\n","This notebook uses the `EfficientNetV2 B2` from KerasCV's collection of pretrained models. To explore other models, simply modify the `preset` in the `CFG` (config). Check the [KerasCV website](https://keras.io/api/keras_cv/models/tasks/image_classifier/) for a list of available pretrained models."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:23.772146Z","iopub.status.busy":"2024-01-21T08:11:23.771871Z","iopub.status.idle":"2024-01-21T08:11:47.907132Z","shell.execute_reply":"2024-01-21T08:11:47.906227Z","shell.execute_reply.started":"2024-01-21T08:11:23.77212Z"},"papermill":{"duration":10.446166,"end_time":"2024-01-14T03:18:49.186176","exception":false,"start_time":"2024-01-14T03:18:38.74001","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Build Classifier\n","model = keras_cv.models.ImageClassifier.from_preset(\n","    CFG.preset, num_classes=CFG.num_classes\n",")\n","\n","# Compile the model  \n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","              loss=LOSS)\n","\n","# Model Sumamry\n","model.summary()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.016209,"end_time":"2024-01-14T03:18:49.21924","exception":false,"start_time":"2024-01-14T03:18:49.203031","status":"completed"},"tags":[]},"source":["# âš“ | LR Schedule\n","\n","A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:47.908637Z","iopub.status.busy":"2024-01-21T08:11:47.908346Z","iopub.status.idle":"2024-01-21T08:11:47.918578Z","shell.execute_reply":"2024-01-21T08:11:47.917684Z","shell.execute_reply.started":"2024-01-21T08:11:47.90861Z"},"papermill":{"duration":0.028945,"end_time":"2024-01-14T03:18:49.264535","exception":false,"start_time":"2024-01-14T03:18:49.23559","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import math\n","\n","def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n","    lr_start, lr_max, lr_min = 5e-5, 6e-6 * batch_size, 1e-5\n","    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n","\n","    def lrfn(epoch):  # Learning rate update function\n","        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n","        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n","        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n","        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n","        elif mode == 'cos':\n","            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n","            phase = math.pi * decay_epoch_index / decay_total_epochs\n","            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n","        return lr\n","\n","    if plot:  # Plot lr curve if plot is True\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n","        plt.xlabel('epoch'); plt.ylabel('lr')\n","        plt.title('LR Scheduler')\n","        plt.show()\n","\n","    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:47.920059Z","iopub.status.busy":"2024-01-21T08:11:47.919711Z","iopub.status.idle":"2024-01-21T08:11:48.208939Z","shell.execute_reply":"2024-01-21T08:11:48.207965Z","shell.execute_reply.started":"2024-01-21T08:11:47.920032Z"},"papermill":{"duration":0.297147,"end_time":"2024-01-14T03:18:49.578089","exception":false,"start_time":"2024-01-14T03:18:49.280942","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.017199,"end_time":"2024-01-14T03:18:49.613648","exception":false,"start_time":"2024-01-14T03:18:49.596449","status":"completed"},"tags":[]},"source":["# ðŸ’¾ | Model Checkpointing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:48.210551Z","iopub.status.busy":"2024-01-21T08:11:48.210251Z","iopub.status.idle":"2024-01-21T08:11:48.21519Z","shell.execute_reply":"2024-01-21T08:11:48.214326Z","shell.execute_reply.started":"2024-01-21T08:11:48.210525Z"},"papermill":{"duration":0.024529,"end_time":"2024-01-14T03:18:49.655708","exception":false,"start_time":"2024-01-14T03:18:49.631179","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["ckpt_cb = keras.callbacks.ModelCheckpoint(\"best_model.keras\",\n","                                         monitor='val_loss',\n","                                         save_best_only=True,\n","                                         save_weights_only=False,\n","                                         mode='min')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.01671,"end_time":"2024-01-14T03:18:49.689354","exception":false,"start_time":"2024-01-14T03:18:49.672644","status":"completed"},"tags":[]},"source":["# ðŸš‚ | Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:11:48.216638Z","iopub.status.busy":"2024-01-21T08:11:48.216319Z","iopub.status.idle":"2024-01-21T08:26:11.991931Z","shell.execute_reply":"2024-01-21T08:26:11.990786Z","shell.execute_reply.started":"2024-01-21T08:11:48.216588Z"},"papermill":{"duration":3374.692199,"end_time":"2024-01-14T04:15:04.398389","exception":false,"start_time":"2024-01-14T03:18:49.70619","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["history = model.fit(\n","    train_ds, \n","    epochs=CFG.epochs,\n","    callbacks=[lr_cb, ckpt_cb], \n","    steps_per_epoch=len(train_df)//CFG.batch_size,\n","    validation_data=valid_ds, \n","    verbose=CFG.verbose\n",")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.693309,"end_time":"2024-01-14T04:15:05.731839","exception":false,"start_time":"2024-01-14T04:15:05.03853","status":"completed"},"tags":[]},"source":["# ðŸ§ª | Prediction"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.632183,"end_time":"2024-01-14T04:15:06.991143","exception":false,"start_time":"2024-01-14T04:15:06.35896","status":"completed"},"tags":[]},"source":["## Load Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:26:11.994508Z","iopub.status.busy":"2024-01-21T08:26:11.994138Z","iopub.status.idle":"2024-01-21T08:26:19.318291Z","shell.execute_reply":"2024-01-21T08:26:19.317485Z","shell.execute_reply.started":"2024-01-21T08:26:11.994479Z"},"papermill":{"duration":20.428261,"end_time":"2024-01-14T04:15:28.044401","exception":false,"start_time":"2024-01-14T04:15:07.61614","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["model.load_weights(\"best_model.keras\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.703901,"end_time":"2024-01-14T04:20:09.745279","exception":false,"start_time":"2024-01-14T04:20:09.041378","status":"completed"},"tags":[]},"source":["## Build Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:26:19.320511Z","iopub.status.busy":"2024-01-21T08:26:19.320221Z","iopub.status.idle":"2024-01-21T08:26:19.366196Z","shell.execute_reply":"2024-01-21T08:26:19.365433Z","shell.execute_reply.started":"2024-01-21T08:26:19.320486Z"},"trusted":true},"outputs":[],"source":["test_paths = test_df.spec2_path.values\n","test_ds = build_dataset(test_paths, batch_size=min(CFG.batch_size, len(test_df)),\n","                         repeat=False, shuffle=False, cache=False, augment=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:26:19.367983Z","iopub.status.busy":"2024-01-21T08:26:19.367379Z","iopub.status.idle":"2024-01-21T08:26:44.828629Z","shell.execute_reply":"2024-01-21T08:26:44.827887Z","shell.execute_reply.started":"2024-01-21T08:26:19.367955Z"},"trusted":true},"outputs":[],"source":["preds = model.predict(test_ds)"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ“© | Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-21T08:26:44.830386Z","iopub.status.busy":"2024-01-21T08:26:44.830108Z","iopub.status.idle":"2024-01-21T08:26:44.873794Z","shell.execute_reply":"2024-01-21T08:26:44.872998Z","shell.execute_reply.started":"2024-01-21T08:26:44.830361Z"},"trusted":true},"outputs":[],"source":["pred_df = test_df[[\"eeg_id\"]].copy()\n","target_cols = [x.lower()+'_vote' for x in CFG.class_names]\n","pred_df[target_cols] = preds.tolist()\n","\n","sub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n","sub_df = sub_df[[\"eeg_id\"]].copy()\n","sub_df = sub_df.merge(pred_df, on=\"eeg_id\", how=\"left\")\n","sub_df.to_csv(\"submission.csv\", index=False)\n","sub_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# ðŸ“Œ | Reference\n","* [HMS-HBAC: ResNet34d Baseline [Training]](https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training) \n","* [EfficientNetB2 Starter - [LB 0.57]](https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4308295,"sourceId":7526248,"sourceType":"datasetVersion"},{"modelInstanceId":4598,"sourceId":6127,"sourceType":"modelInstanceVersion"}],"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"papermill":{"default_parameters":{},"duration":3846.080383,"end_time":"2024-01-14T04:20:19.064569","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-01-14T03:16:12.984186","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"08983a9c6aff42578980f4f7113c3ee2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4411aefc021d46d0ada7b645eb53ec48","placeholder":"â€‹","style":"IPY_MODEL_09a10a8cf9334c51857397ed50398c8e","value":"Searching best thr : 100%"}},"09a10a8cf9334c51857397ed50398c8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f3989a0c01248328e16875075e9d1c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08983a9c6aff42578980f4f7113c3ee2","IPY_MODEL_22cfcc0a7cc6455fbf3bb7c788c8a4e1","IPY_MODEL_c8392e8075224e3b8a020a16c1a08447"],"layout":"IPY_MODEL_6cec9a2c2fac450d87248aed8dd62f86"}},"22cfcc0a7cc6455fbf3bb7c788c8a4e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dffe80502d954bdea0bbb6353dbf5515","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ce1b34a4f864a42a6619eec82311eb0","value":20}},"4411aefc021d46d0ada7b645eb53ec48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cec9a2c2fac450d87248aed8dd62f86":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce1b34a4f864a42a6619eec82311eb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83fe40a0b8f047cc8602206909d42361":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9384babdb7054d55aecdf3e989ddc926":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8392e8075224e3b8a020a16c1a08447":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83fe40a0b8f047cc8602206909d42361","placeholder":"â€‹","style":"IPY_MODEL_9384babdb7054d55aecdf3e989ddc926","value":" 20/20 [04:34&lt;00:00, 12.66s/it]"}},"dffe80502d954bdea0bbb6353dbf5515":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
